\relax 
\newlabel{FirstPage}{{}{1}{}{}{}}
\@writefile{toc}{\contentsline {title}{Nonparametric Clustering from Energy Statistics}{1}{}}
\@writefile{toc}{\contentsline {abstract}{Abstract}{1}{}}
\citation{Szkely2013}
\citation{Sejdinovic2013}
\citation{Szkely2013}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background on Energy Statistics and RKHS}{2}{}}
\newlabel{sec:background}{{II}{2}{}{}{}}
\newlabel{eq:energy}{{1}{2}{}{}{}}
\newlabel{eq:energy2}{{2}{2}{}{}{}}
\newlabel{eq:negative_type}{{3}{2}{}{}{}}
\citation{Sejdinovic2013}
\citation{Aronszajn}
\newlabel{eq:energy3}{{4}{3}{}{}{}}
\citation{Gretton2012}
\citation{Berg1984}
\citation{Sejdinovic2013}
\citation{Sejdinovic2013}
\citation{Szkely2013}
\newlabel{eq:mmd}{{5}{4}{}{}{}}
\newlabel{eq:mmd2}{{6}{4}{}{}{}}
\newlabel{eq:inner_data}{{7}{4}{}{}{}}
\newlabel{eq:kernel_semimetric}{{8}{4}{}{}{}}
\newlabel{eq:gen_kernel}{{9}{4}{}{}{}}
\newlabel{eq:Erho}{{10}{4}{}{}{}}
\citation{Szkely2013}
\newlabel{eq:g_def}{{11}{5}{}{}{}}
\newlabel{eq:within}{{12}{5}{}{}{}}
\newlabel{eq:between}{{13}{5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Clustering Based on Energy Statistics}{5}{}}
\newlabel{sec:clustering_theory}{{III}{5}{}{}{}}
\newlabel{th:minimize}{{1}{6}{}{}{}}
\newlabel{eq:minimize}{{14}{6}{}{}{}}
\newlabel{eq:kernel_matrix}{{16}{6}{}{}{}}
\newlabel{eq:label_matrix}{{17}{7}{}{}{}}
\newlabel{th:qcqp2}{{2}{7}{}{}{}}
\newlabel{eq:qcqp2}{{18}{7}{}{}{}}
\newlabel{eq:W2}{{19}{7}{}{}{}}
\newlabel{eq:max_prob}{{20}{7}{}{}{}}
\newlabel{eq:qcqp}{{22}{7}{}{}{}}
\citation{NgJordan}
\citation{Dhillon}
\citation{Dhillon}
\newlabel{eq:kernel_kmeans}{{24}{9}{}{}{}}
\newlabel{th:kernel_kmeans}{{3}{9}{}{}{}}
\newlabel{eq:J}{{25}{9}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Two-Class Problem in One Dimension}{10}{}}
\newlabel{sec:twoclass}{{IV}{10}{}{}{}}
\newlabel{eq:g_ind}{{28}{10}{}{}{}}
\newlabel{eq:g1d}{{29}{10}{}{}{}}
\citation{Vassilvitskii}
\newlabel{algo1d}{{1}{11}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces   Approximate solution to \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 14{}{}{}\hbox {}\unskip \@@italiccorr )}} for a two-class problem in one dimension. \hspace  {\fill } }}{11}{}}
\newlabel{eq:w1d}{{30}{11}{}{}{}}
\newlabel{eq:accuracy}{{31}{11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces   We cluster data using Algorithm\nobreakspace  {}1{}{}{}\hbox {} ($1D$-Energy in the plots), GMM, and $k$-means. We use \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 31{}{}{}\hbox {}\unskip \@@italiccorr )}} to evaluate cluster quality. Both clusters have the same number of points, which are increased in each experiment. (a) $x\sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1,\sigma _1) + \mathcal  {N}(\mu _2,\sigma _2) \right )$ with $\mu _1 = 0$, $\mu _2 = 5$, $\sigma _1 = 1$, and $\sigma _2 = 2$. (b) $x\sim \genfrac  {}{}{}1{1}{2}\left ( e^{\mathcal  {N}(\mu _1,\sigma _1)} + e^{\mathcal  {N}(\mu _2,\sigma _2)} \right )$ with $\mu _1 = 0$, $\mu _2 = -1.5$, $\sigma _1 = 0.3$, and $\sigma _2 = 1.5$. }}{12}{}}
\newlabel{fig:1d}{{1}{12}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Iterative Algorithm for Energy Statistics Clustering}{12}{}}
\newlabel{sec:algo}{{V}{12}{}{}{}}
\citation{Dhillon}
\newlabel{eq:maxQ}{{32}{13}{}{}{}}
\newlabel{eq:costxij}{{33}{13}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Kernel $\bm  {k}$-Means Algorithm}{13}{}}
\newlabel{eq:Jell}{{34}{13}{}{}{}}
\newlabel{kmeans_algo}{{2}{14}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces  Kernel $k$-means algorithm to find an approximate solution to \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 18{}{}{}\hbox {}\unskip \@@italiccorr )}}. \hspace  {\fill } }}{14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Energy Cost Algorithm}{14}{}}
\newlabel{eq:changeQ}{{35}{14}{}{}{}}
\newlabel{algo}{{3}{15}{}{}{}}
\newlabel{stepmove}{{V\tmspace  +\thinmuskip {.1667em}B}{15}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces  Energy cost algorithm to find an approximate solution to \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 18{}{}{}\hbox {}\unskip \@@italiccorr )}}. \hspace  {\fill } }}{15}{}}
\citation{Vassilvitskii}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Numerical Experiments}{16}{}}
\newlabel{sec:numerics}{{VI}{16}{}{}{}}
\newlabel{eq:gauss1}{{37}{16}{}{}{}}
\newlabel{eq:gauss2}{{38}{16}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces   Two clusters with normally distributed data, with $100$ points in each cluster. We analyse the effect of ambient dimension while keeping Bayes error fixed. (a) We increase $D$ as described in \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 37{}{}{}\hbox {}\unskip \@@italiccorr )}}. The blue line correspond to Algorithm\nobreakspace  {}3{}{}{}\hbox {}, while the magenta line corresponds to Algorithm\nobreakspace  {}2{}{}{}\hbox {}. (b) The same but with data following \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 38{}{}{}\hbox {}\unskip \@@italiccorr )}}. In both experiments one notice a slightly better accuracy of Algorithm\nobreakspace  {}3{}{}{}\hbox {} compared to the other ones. }}{17}{}}
\newlabel{fig:gauss}{{2}{17}{}{}{}}
\newlabel{eq:gauss3}{{39}{17}{}{}{}}
\bibdata{energy_clusteringNotes,biblio.bib}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces   (a) Previous algorithms for unbalanced clusters, according to \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 39{}{}{}\hbox {}\unskip \@@italiccorr )}}. (b) The same experiment as in Figure\nobreakspace  {}2{}{}{}\hbox {}a but for lognormal data as $x\sim \genfrac  {}{}{}1{1}{2}\left ( e^{\mathcal  {N}(\mu _1,\Sigma _1)} + e^{\mathcal  {N}(\mu _2,\Sigma _2)} \right )$ with $\mu _1 = (0,\dotsc  ,0)^\top $, $\mu _2 = 0.5\times (1,\dotsc  ,1,0,\dotsc  ,0)^\top $ with signal in $d=10$, $\Sigma _1 = 0.3 \times I_D$, and $\Sigma _2=I_D$. One see a clear advantage of energy statistics clustering. The extra green line correspond to $\rho (x,y) = \delimiter "026B30D  x-y\delimiter "026B30D ^{1/2}$. }}{18}{}}
\newlabel{fig:unbalanced}{{3}{18}{}{}{}}
\newlabel{eq:cigar}{{40}{18}{}{}{}}
\newlabel{eq:rho_loc}{{41}{18}{}{}{}}
\newlabel{eq:rho_sin}{{42}{18}{}{}{}}
\bibcite{Szkely2013}{{1}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces   (a) Parallel cigars generated from \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 40{}{}{}\hbox {}\unskip \@@italiccorr )}} with $100$ points in each class. Use use energy clustering with $\rho = \delimiter "026B30D  x - y\delimiter "026B30D ^{1/2}$. (b) Two concentric circles with $150$ points in each class. We use the semimetric \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 41{}{}{}\hbox {}\unskip \@@italiccorr )}}. (c) Two concentric spirals with $150$ points in each class. We use the semimetric \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 42{}{}{}\hbox {}\unskip \@@italiccorr )}}. }}{19}{}}
\newlabel{fig:weird}{{4}{19}{}{}{}}
\bibcite{Sejdinovic2013}{{2}{}{{}}{{}}}
\bibcite{Aronszajn}{{3}{}{{}}{{}}}
\bibcite{Gretton2012}{{4}{}{{}}{{}}}
\bibcite{Berg1984}{{5}{}{{}}{{}}}
\bibcite{NgJordan}{{6}{}{{}}{{}}}
\bibcite{Dhillon}{{7}{}{{}}{{}}}
\bibcite{Vassilvitskii}{{8}{}{{}}{{}}}
\bibstyle{unsrt}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Acknowledgements}{20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{20}{}}
\newlabel{LastBibItem}{{8}{20}{}{}{}}
\newlabel{LastPage}{{}{20}{}{}{}}
