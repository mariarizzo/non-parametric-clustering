\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Szkely2013}
\citation{RizzoVariance}
\citation{RizzoClustering}
\citation{Kgroups}
\citation{Szkely2013}
\citation{Lyons}
\citation{Sejdinovic2013}
\citation{Lloyd,MacQueen,Forgy}
\citation{Lloyd}
\citation{Smola,Girolami}
\citation{Mercer}
\citation{Girolami}
\citation{Dhillon2,Dhillon}
\citation{Filippone}
\citation{Kgroups}
\citation{Hartigan}
\citation{Kgroups}
\citation{Telgarsky,Slonin}
\citation{Szkely2013,Lyons}
\citation{Sejdinovic2013}
\citation{Szkely2013}
\citation{Szkely2013}
\citation{Aronszajn}
\newlabel{sec:background}{{2}{2}{}{section.2}{}}
\newlabel{eq:energy3}{{1}{2}{}{equation.2.1}{}}
\newlabel{eq:rho_standard}{{2}{2}{}{equation.2.2}{}}
\newlabel{eq:g_def}{{3}{2}{}{equation.2.3}{}}
\newlabel{eq:within}{{4}{2}{}{equation.2.4}{}}
\newlabel{eq:between}{{5}{2}{}{equation.2.5}{}}
\citation{Gretton2012}
\citation{Berg1984}
\citation{Sejdinovic2013}
\citation{Sejdinovic2013}
\citation{Kgroups}
\newlabel{eq:mmd}{{6}{3}{}{equation.2.6}{}}
\newlabel{eq:mmd2}{{7}{3}{}{equation.2.7}{}}
\newlabel{eq:kernel_semimetric}{{8}{3}{}{equation.2.8}{}}
\newlabel{eq:gen_kernel}{{9}{3}{}{equation.2.9}{}}
\newlabel{eq:Erho}{{10}{3}{}{equation.2.10}{}}
\newlabel{sec:clustering_theory}{{3}{3}{}{section.3}{}}
\newlabel{th:minimize}{{1}{3}{}{theorem.1}{}}
\newlabel{eq:minimize}{{11}{3}{}{equation.3.11}{}}
\newlabel{eq:kernel_matrix}{{12}{3}{}{equation.3.12}{}}
\newlabel{eq:label_matrix}{{13}{3}{}{equation.3.13}{}}
\citation{Lloyd}
\citation{Dhillon2,Dhillon}
\citation{Dhillon2,Dhillon}
\citation{Hartigan}
\citation{Dhillon2,Dhillon}
\newlabel{th:qcqp2}{{2}{4}{}{theorem.2}{}}
\newlabel{eq:qcqp2}{{14}{4}{}{equation.3.14}{}}
\newlabel{eq:kernel_kmeans}{{15}{4}{}{equation.3.15}{}}
\newlabel{th:kernel_kmeans}{{3}{4}{}{theorem.3}{}}
\newlabel{sec:algo}{{4}{4}{}{section.4}{}}
\newlabel{eq:maxQ}{{16}{4}{}{equation.4.16}{}}
\newlabel{eq:costxij}{{17}{4}{}{equation.4.17}{}}
\citation{Kgroups}
\citation{Dhillon2,Dhillon}
\citation{Telgarsky}
\citation{Telgarsky}
\citation{Telgarsky}
\citation{Telgarsky}
\citation{Slonin}
\newlabel{eq:changeQ}{{19}{5}{}{equation.4.19}{}}
\newlabel{algo}{{1}{5}{}{algorithm.1}{}}
\citation{scikit-learn}
\citation{Vassilvitskii}
\citation{Malik}
\citation{Dhillon2,Dhillon}
\newlabel{sec:numerics}{{5}{6}{}{section.5}{}}
\newlabel{eq:test_metrics}{{21}{6}{}{equation.5.21}{}}
\newlabel{eq:accuracy}{{22}{6}{}{equation.5.22}{}}
\newlabel{fig:1D}{{1}{6}{Clustering results for one dimensional data \eqref {eq:uni_normal}--\eqref {eq:uni_params}. \emph {Top Left:} Probability density of \eqref {eq:uni_normal}. \emph {Top Right:} Probability density of \eqref {eq:uni_lognormal}. \emph {Bottom Left:} Clustering data from \eqref {eq:uni_normal}. \emph {Bottom Right:} Clustering data from \eqref {eq:uni_lognormal}. The dashed lines show the optimal Bayes accuracy, which in both cases are $\approx 0.88$}{figure.1}{}}
\newlabel{eq:uni_normal}{{23}{6}{}{equation.5.23}{}}
\newlabel{eq:uni_lognormal}{{24}{6}{}{equation.5.24}{}}
\newlabel{eq:uni_params}{{25}{6}{}{equation.5.25}{}}
\newlabel{eq:gauss1}{{26}{6}{}{equation.5.26}{}}
\newlabel{fig:gauss}{{2}{7}{High dimensional Gaussian mixtures. \emph {Left:} Parameters as in \eqref {eq:gauss1}. \emph {Right:} Parameters as in \eqref {eq:gauss2}. The dashed lines are Bayes accuracy}{figure.2}{}}
\newlabel{eq:gauss2}{{27}{7}{}{equation.5.27}{}}
\newlabel{eq:20gauss}{{28}{7}{}{equation.5.28}{}}
\newlabel{fig:consist}{{3}{7}{Normal \emph {(Left)} and lognormal \emph {(Right)} mixtures with parameters \eqref {eq:20gauss}. We use different kernels for $\mathcal {E}^H$-clustering. Bayes accuracy is $\approx 0.9$. The two plots in the \emph {Bottom} show the difference in accuracy between $\mathcal {E}^H$-clustering versus kernel $k$-means and spectral clustering, with $\widetilde {\rho }_1$}{figure.3}{}}
\newlabel{fig:other}{{4}{7}{\emph {Left}: Parallel cigars, $200$ points each. \emph {Center and Right:} Two and three concentric circles, respectively, with Gaussian noise. $400$ points for each class}{figure.4}{}}
\citation{vonLuxburg2007}
\citation{Tibshirani2001}
\newlabel{table:other}{{1}{8}{Clustering data from Figure~\ref {fig:other}}{table.1}{}}
\newlabel{fig:synapse}{{5}{8}{Clustering synapse dataset. Plots in order from \emph {left} to \emph {right}. \emph {First:} Eigenvalues of random walk Laplacian. We choose $k=6$ since its the first time we see a peak. We use energy clustering with the two semimetrics $\rho _1$ and $\widehat {\rho }_2$; see \eqref {eq:test_metrics}. \emph {Second:} Heat map of the cluster means versus features using energy clustering with standard metric $\rho _1$ from energy statistics. \emph {Third:} Clustered points projected into the two principal components, using $\rho _1$. \emph {Fourth:} Heat map of the cluster means versus features using energy clustering with Gaussian semimetric $\widehat {\rho }_2$. \emph {Fifth:} Clustered points projected into the two principal components, using $\widehat {\rho }_2$}{figure.5}{}}
\newlabel{sec:conclusion}{{6}{8}{}{section.6}{}}
\bibstyle{icml2018}
\bibdata{biblio.bib}
\bibcite{Aronszajn}{{1}{1950}{{Aronszajn}}{{}}}
\bibcite{Vassilvitskii}{{2}{2007}{{Arthur \& Vassilvitskii}}{{Arthur and Vassilvitskii}}}
\bibcite{Berg1984}{{3}{1984}{{Berg et~al.}}{{Berg, Christensen, and Ressel}}}
\bibcite{Dhillon2}{{4}{2004}{{Dhillon et~al.}}{{Dhillon, Guan, and Kulis}}}
\bibcite{Dhillon}{{5}{2007}{{Dhillon et~al.}}{{Dhillon, Guan, and Kulis}}}
\bibcite{Filippone}{{6}{2008}{{Filippone et~al.}}{{Filippone, Camastra, Masulli, and Rovetta}}}
\bibcite{Forgy}{{7}{1965}{{Forgy}}{{}}}
\bibcite{Girolami}{{8}{2002}{{Girolami}}{{}}}
\bibcite{Gretton2012}{{9}{2012}{{Gretton et~al.}}{{Gretton, Borgwardt, Rasch, Sch{\"olkopf}, and Smola}}}
\bibcite{Hartigan}{{10}{1979}{{Hartigan \& Wong}}{{Hartigan and Wong}}}
\bibcite{MacQueen}{{11}{1967}{{J. B. MacQueen}}{{}}}
\bibcite{Kgroups}{{12}{2015}{{Li}}{{}}}
\bibcite{Lloyd}{{13}{1982}{{Lloyd}}{{}}}
\bibcite{Lyons}{{14}{2013}{{Lyons}}{{}}}
\bibcite{Mercer}{{15}{1909}{{Mercer}}{{}}}
\bibcite{scikit-learn}{{16}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{RizzoVariance}{{17}{2010}{{Rizzo \& Sz{\'e}kely}}{{Rizzo and Sz{\'e}kely}}}
\bibcite{Smola}{{18}{1998}{{Sch\"{o}lkopf et~al.}}{{Sch\"{o}lkopf, Smola, and M\"{u}ller}}}
\bibcite{Sejdinovic2013}{{19}{2013}{{Sejdinovic et~al.}}{{Sejdinovic, Sriperumbudur, Gretton, and Fukumizu}}}
\bibcite{Malik}{{20}{2000}{{Shi \& Malik}}{{Shi and Malik}}}
\bibcite{Slonin}{{21}{2013}{{Slonim et~al.}}{{Slonim, Aharoni, and Crammer}}}
\bibcite{RizzoClustering}{{22}{2005}{{Sz{\'e}kely \& Rizzo}}{{Sz{\'e}kely and Rizzo}}}
\bibcite{Szkely2013}{{23}{2013}{{Sz{\'e}kely \& Rizzo}}{{Sz{\'e}kely and Rizzo}}}
\bibcite{Telgarsky}{{24}{2010}{{Telgarsky \& Vattani}}{{Telgarsky and Vattani}}}
\bibcite{Tibshirani2001}{{25}{2001}{{Tibshirani et~al.}}{{Tibshirani, Walther, and Hastie}}}
\bibcite{vonLuxburg2007}{{26}{2007}{{von Luxburg}}{{}}}
\newlabel{eq:W2}{{30}{11}{Acknowledgements}{equation.A.30}{}}
\newlabel{eq:max_prob}{{31}{11}{Acknowledgements}{equation.A.31}{}}
\newlabel{eq:qcqp}{{33}{11}{Acknowledgements}{equation.A.33}{}}
\newlabel{eq:J}{{35}{11}{Acknowledgements}{equation.A.35}{}}
