\relax 
\newlabel{FirstPage}{{}{1}{}{}{}}
\@writefile{toc}{\contentsline {title}{Notes about Statistics, Clustering, Graphs, \ldots  }{1}{}}
\@writefile{toc}{\contentsline {abstract}{Abstract}{1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Experiments using Energy Statistics and One-Dimensional Random Projections}{2}{}}
\newlabel{eq:accuracy}{{1}{2}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, I) + \mathcal  {N}(\mu _2, I)\right )$ where $\mu _1 = (0,0)^T$ and $\mu _2=(4,0)^T$, and $1000$ points on each cluster. We run the experiment three times. We choose only $20$ random projections. }}{3}{}}
\newlabel{fig:2d_gauss_sep}{{1}{3}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma ) + \mathcal  {N}(\mu _2, \Sigma )\right )$ where $\mu _1 = (0,0)^T$, $\mu _2=(6,0)^T$, and $\Sigma = \left ( \begin{smallmatrix} 1 & 0 \\ 0 & 20 \end{smallmatrix} \right )$, and $2000$ points on each cluster. We run the experiment three times. We use $30$ random projections. }}{3}{}}
\newlabel{fig:cigar}{{2}{3}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0)^T$, $\mu _2=(2,1)^T$, $\Sigma _1 = \left ( \begin{smallmatrix} 0.5 & -0.8 \\ -0.8 & 15 \end{smallmatrix} \right )$, $\Sigma _2 = \left ( \begin{smallmatrix} 15 & 1 \\ 1 & 1 \end{smallmatrix} \right )$, and $2000$ points on each cluster. We run the experiment three times, with 30 random projections. }}{4}{}}
\newlabel{fig:weird1}{{3}{4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  High dimensions. We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, I_D) + \mathcal  {N}(\mu _2, I_D)\right )$ where $\mu _1 = (0,0,\dotsc  ,0)^T$, $\mu _2=(3,0,\dots  ,0)^T$, and $1000$ points on each cluster. We do 100 random projections. We show the two principal components of the data in the plot above. }}{4}{}}
\newlabel{fig:highd}{{4}{4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Conclusions}{4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  High dimensions. We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, I_D) + \mathcal  {N}(\mu _2, I_D)\right )$ where $\mu _1 = (1,0,1,\dotsc  ,0,1)^T$, $\mu _2 = (-1,0,-1,\dotsc  ,0,-1)^T$, i.e. the even dimensions are shifted at $+1$ and $-1$, respectivelly. We have $1000$ points on each cluster. We do 100 random projections. We show the two principal components of the data in the plot above. When we have more signal we can see that random projections with $\mathcal  {E}$ is much superior to random projections and $k$-means++. }}{5}{}}
\newlabel{fig:highd}{{5}{5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Energy Statistics Based Clustering}{5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0)^T$, $\mu _2=(4,0)^T$, $\Sigma _1 = \Sigma _2 = I$, and $500$ points on each cluster. We run the experiment three times, with 20 random projections as initialization. }}{6}{}}
\newlabel{fig:weird1}{{6}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0)^T$, $\mu _2=(2,0)^T$, $\Sigma _1 = \Sigma _2 = I$, and $500$ points on each cluster. We run the experiment three times, with 20 random projections as initialization. }}{6}{}}
\newlabel{fig:weird1}{{7}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0)^T$, $\mu _2=(4,0)^T$, $\Sigma _1 = I$, $\Sigma _2 = \left ( \begin{smallmatrix} 1 & 0 \\ 1 & 20 \end{smallmatrix}\right )$ and $500$ points on each cluster. We run the experiment three times, with 20 random projections as initialization. }}{7}{}}
\newlabel{fig:weird1}{{8}{7}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}1$D$ Energy Clustering}{8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = 0$, $\mu _2=2$, $\Sigma _1 = \Sigma _2 = 1$, and $500$ points on each cluster. We run the experiment three times, using $k$-means++ as initialization in kernel. }}{8}{}}
\newlabel{fig:1dgaus1}{{9}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = 0$, $\mu _2=1$, $\Sigma _1 = \Sigma _2 = 1$, and $500$ points on each cluster. We run the experiment three times, using $k$-means++ as initialization in kernel. }}{9}{}}
\newlabel{fig:1dgaus1}{{10}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \qopname  \relax o{log}\mathcal  {N}(\mu _1, \Sigma _1) + \qopname  \relax o{log}\mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = 0$, $\mu _2=1.5$, $\Sigma _1 = 0.25$, $ \Sigma _2 = 0.5$, and $500$ points on each cluster. We run the experiment three times, using $k$-means++ as initialization in kernel. }}{9}{}}
\newlabel{fig:1dloggaus1}{{11}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = 0$, $\mu _2=2$, $\Sigma _1 = 1$, $ \Sigma _2 = 3$, $n_1 = 100$, $n_2=200$. For each experiment we run several times and pick the answer with optimal objective function. }}{10}{}}
\newlabel{fig:1dloggaus1}{{12}{10}{}{}{}}
\bibdata{discussionNotes}
\bibstyle{apsrev4-1}
\citation{REVTEX41Control}
\citation{apsrev41Control}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Energy Clustering Higher $D$}{11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \mathcal  {N}(\mu _1, \Sigma _1) + \mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0,0,0)^T$, $\mu _2=(1.5, 0,0,0)^T$, $\Sigma _1 = \left ( \begin{smallmatrix} 0.6 & 0.2 & 0.2 & 0.2 \\ 0.2 & 0.6 & 0.2 & 0.2 \\ 0.2 & 0.2 & 0.6 & 0.2 \\ 0.2 & 0.2 & 0.2 & 0.6 \\ \end{smallmatrix} \right )$, $\Sigma _2 = \left ( \begin{smallmatrix} 0.5 & 0 & 0 & 0 \\ 0 & 0.5 & 0 & 0 \\ 0 & 0 & 0.5 & 0 \\ 0 & 0 & 0 & 0.5 \\ \end{smallmatrix} \right )$, $n_1=200$, $n_2=200$. We run the experiments few times and pick the answer with best objective function. }}{11}{}}
\newlabel{fig:1dloggaus1}{{13}{11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \qopname  \relax o{log}\mathcal  {N}(\mu _1, \Sigma _1) + \qopname  \relax o{log}\mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0)^T$, $\mu _2=(1.5, 0)^T$, $\Sigma _1 = \left ( \begin{smallmatrix} 0.25 & 0 \\ 0 & 0.25 \end{smallmatrix} \right )$, $\Sigma _2 = \left ( \begin{smallmatrix} 0.5 & 0 \\ 0 & 0.5 \end{smallmatrix} \right )$, and $100$ points on each cluster. We run the experiment three times, using $k$-means++ as initialization in kernel. EClust is extremelly slow. }}{11}{}}
\newlabel{fig:1dloggaus1}{{14}{11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces  We have $x \sim \genfrac  {}{}{}1{1}{2}\left ( \qopname  \relax o{log}\mathcal  {N}(\mu _1, \Sigma _1) + \qopname  \relax o{log}\mathcal  {N}(\mu _2, \Sigma _2)\right )$ where $\mu _1 = (0,0,0,0)^T$, $\mu _2=(1.5, 1.5,0,0)^T$, $\Sigma _1 = \left ( \begin{smallmatrix} 0.25 & 0 & 0 & 0 \\ 0 & 0.25 & 0 & 0 \\ 0 & 0 & 0.25 & 0 \\ 0 & 0 & 0 & 0.25 \\ \end{smallmatrix} \right )$, $\Sigma _2 = \left ( \begin{smallmatrix} 0.5 & 0 & 0 & 0 \\ 0 & 0.5 & 0 & 0 \\ 0 & 0 & 0.5 & 0 \\ 0 & 0 & 0 & 0.5 \\ \end{smallmatrix} \right )$, and $100$ points on each cluster. We run the experiment three times, using $k$-means++ as initialization in kernel. EClust is extremelly slow. }}{12}{}}
\newlabel{fig:1dloggaus1}{{15}{12}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces  We generate two circles with random noise. First circle has radius $1$ and a gaussian noise of size $0.2$. Second circle has radius $.2$ and a gaussian noise of size $0.2$. We have 200 points on each class. }}{12}{}}
\newlabel{fig:circles}{{16}{12}{}{}{}}
\newlabel{LastPage}{{}{12}{}{}{}}
